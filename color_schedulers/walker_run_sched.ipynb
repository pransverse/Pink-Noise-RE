{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7517413,"sourceType":"datasetVersion","datasetId":4378788},{"sourceId":7531623,"sourceType":"datasetVersion","datasetId":4386668}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":41858.164034,"end_time":"2024-02-07T09:10:03.448979","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-06T21:32:25.284945","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install dm_control\n# !pip install pink-noise-rl\n!pip install wandb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":32.497724,"end_time":"2024-02-06T21:33:00.681977","exception":false,"start_time":"2024-02-06T21:32:28.184253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:14:19.963061Z","iopub.execute_input":"2024-02-11T14:14:19.963513Z","iopub.status.idle":"2024-02-11T14:14:43.735998Z","shell.execute_reply.started":"2024-02-11T14:14:19.963481Z","shell.execute_reply":"2024-02-11T14:14:43.734987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch as th\ndevice = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"papermill":{"duration":3.862202,"end_time":"2024-02-06T21:33:04.554138","exception":false,"start_time":"2024-02-06T21:33:00.691936","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:14:43.738144Z","iopub.execute_input":"2024-02-11T14:14:43.738523Z","iopub.status.idle":"2024-02-11T14:14:45.617798Z","shell.execute_reply.started":"2024-02-11T14:14:43.738486Z","shell.execute_reply":"2024-02-11T14:14:45.616789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gym import core, spaces\nfrom dm_control import suite\nfrom dm_env import specs\nimport numpy as np\n\n\ndef _spec_to_box(spec, dtype):\n    def extract_min_max(s):\n        assert s.dtype == np.float64 or s.dtype == np.float32\n        dim = int(np.prod(s.shape))\n        if type(s) == specs.Array:\n            bound = np.inf * np.ones(dim, dtype=np.float32)\n            return -bound, bound\n        elif type(s) == specs.BoundedArray:\n            zeros = np.zeros(dim, dtype=np.float32)\n            return s.minimum + zeros, s.maximum + zeros\n\n    mins, maxs = [], []\n    for s in spec:\n        mn, mx = extract_min_max(s)\n        mins.append(mn)\n        maxs.append(mx)\n    low = np.concatenate(mins, axis=0).astype(dtype)\n    high = np.concatenate(maxs, axis=0).astype(dtype)\n    assert low.shape == high.shape\n    return spaces.Box(low, high, dtype=dtype)\n\n\ndef _flatten_obs(obs):\n    obs_pieces = []\n    for v in obs.values():\n        flat = np.array([v]) if np.isscalar(v) else v.ravel()\n        obs_pieces.append(flat)\n    return np.concatenate(obs_pieces, axis=0)\n\n\nclass DMCWrapper(core.Env):\n    def __init__(\n        self,\n        domain_name,\n        task_name,\n        task_kwargs=None,\n        visualize_reward=False,\n        from_pixels=False,\n        height=84,\n        width=84,\n        camera_id=0,\n        frame_skip=1,\n        environment_kwargs=None,\n        channels_first=True\n    ):\n#         assert 'random' in task_kwargs, 'please specify a seed, for deterministic behaviour'\n        self._from_pixels = from_pixels\n        self._height = height\n        self._width = width\n        self._camera_id = camera_id\n        self._frame_skip = frame_skip\n        self._channels_first = channels_first\n\n        # create task\n        self._env = suite.load(\n            domain_name=domain_name,\n            task_name=task_name,\n            task_kwargs=task_kwargs,\n            visualize_reward=visualize_reward,\n            environment_kwargs=environment_kwargs\n        )\n\n        # true and normalized action spaces\n        self._true_action_space = _spec_to_box([self._env.action_spec()], np.float32)\n        self._norm_action_space = spaces.Box(\n            low=-1.0,\n            high=1.0,\n            shape=self._true_action_space.shape,\n            dtype=np.float32\n        )\n\n        # create observation space\n        if from_pixels:\n            shape = [3, height, width] if channels_first else [height, width, 3]\n            self._observation_space = spaces.Box(\n                low=0, high=255, shape=shape, dtype=np.uint8\n            )\n        else:\n            self._observation_space = _spec_to_box(\n                self._env.observation_spec().values(),\n                np.float64\n            )\n            \n        self._state_space = _spec_to_box(\n            self._env.observation_spec().values(),\n            np.float64\n        )\n        \n        self.current_state = None\n\n        # set seed\n        self.seed(seed=996)\n\n    def __getattr__(self, name):\n        return getattr(self._env, name)\n\n    def _get_obs(self, time_step):\n        if self._from_pixels:\n            obs = self.render(\n                height=self._height,\n                width=self._width,\n                camera_id=self._camera_id\n            )\n            if self._channels_first:\n                obs = obs.transpose(2, 0, 1).copy()\n        else:\n            obs = _flatten_obs(time_step.observation)\n        return obs\n\n    def _convert_action(self, action):\n        action = action.astype(np.float64)\n        true_delta = self._true_action_space.high - self._true_action_space.low\n        norm_delta = self._norm_action_space.high - self._norm_action_space.low\n        action = (action - self._norm_action_space.low) / norm_delta\n        action = action * true_delta + self._true_action_space.low\n        action = action.astype(np.float32)\n        return action\n\n    @property\n    def observation_space(self):\n        return self._observation_space\n\n    @property\n    def state_space(self):\n        return self._state_space\n\n    @property\n    def action_space(self):\n        return self._norm_action_space\n\n    @property\n    def reward_range(self):\n        return 0, self._frame_skip\n\n    def seed(self, seed):\n        self._true_action_space.seed(seed)\n        self._norm_action_space.seed(seed)\n        self._observation_space.seed(seed)\n\n    def step(self, action):\n        assert self._norm_action_space.contains(action)\n        action = self._convert_action(action)\n        assert self._true_action_space.contains(action)\n        reward = 0\n        extra = {'internal_state': self._env.physics.get_state().copy()}\n\n        for _ in range(self._frame_skip):\n            time_step = self._env.step(action)\n            reward += time_step.reward or 0\n            done = time_step.last()\n            if done:\n                break\n        obs = self._get_obs(time_step)\n        self.current_state = _flatten_obs(time_step.observation)\n        extra['discount'] = time_step.discount\n        return obs, reward, done, extra\n\n    def reset(self):\n        time_step = self._env.reset()\n        self.current_state = _flatten_obs(time_step.observation)\n        obs = self._get_obs(time_step)\n        return obs\n\n    def render(self, mode='rgb_array', height=None, width=None, camera_id=0):\n        assert mode == 'rgb_array', 'only support rgb_array mode, given %s' % mode\n        height = height or self._height\n        width = width or self._width\n        camera_id = camera_id or self._camera_id\n        return self._env.physics.render(\n            height=height, width=width, camera_id=camera_id\n        )","metadata":{"papermill":{"duration":1.020321,"end_time":"2024-02-06T21:33:05.584066","exception":false,"start_time":"2024-02-06T21:33:04.563745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:34:25.559230Z","iopub.execute_input":"2024-02-11T14:34:25.560195Z","iopub.status.idle":"2024-02-11T14:34:25.589983Z","shell.execute_reply.started":"2024-02-11T14:34:25.560159Z","shell.execute_reply":"2024-02-11T14:34:25.588891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom numpy.fft import irfft, rfftfreq\n\n\ndef powerlaw_psd_gaussian(exponent, size, fmin=0, rng=None):\n    \"\"\"Gaussian (1/f)**beta noise.\n\n    Based on the algorithm in:\n    Timmer, J. and Koenig, M.:\n    On generating power law noise.\n    Astron. Astrophys. 300, 707-710 (1995)\n\n    Normalised to unit variance\n\n    Parameters:\n    -----------\n\n    exponent : float\n        The power-spectrum of the generated noise is proportional to\n\n        S(f) = (1 / f)**beta\n        flicker / pink noise:   exponent beta = 1\n        brown noise:            exponent beta = 2\n\n        Furthermore, the autocorrelation decays proportional to lag**-gamma\n        with gamma = 1 - beta for 0 < beta < 1.\n        There may be finite-size issues for beta close to one.\n\n    shape : int or iterable\n        The output has the given shape, and the desired power spectrum in\n        the last coordinate. That is, the last dimension is taken as time,\n        and all other components are independent.\n\n    fmin : float, optional\n        Low-frequency cutoff.\n        Default: 0 corresponds to original paper.\n\n        The power-spectrum below fmin is flat. fmin is defined relative\n        to a unit sampling rate (see numpy's rfftfreq). For convenience,\n        the passed value is mapped to max(fmin, 1/samples) internally\n        since 1/samples is the lowest possible finite frequency in the\n        sample. The largest possible value is fmin = 0.5, the Nyquist\n        frequency. The output for this value is white noise.\n\n    rng : np.random.Generator, optional\n        Random number generator (for reproducibility). If not passed, a new\n        random number generator is created by calling\n        `np.random.default_rng()`.\n\n\n    Returns\n    -------\n    out : array\n        The samples.\n\n\n    Examples:\n    ---------\n\n    >>> # generate 1/f noise == pink noise == flicker noise\n    >>> import colorednoise as cn\n    >>> y = cn.powerlaw_psd_gaussian(1, 5)\n    \"\"\"\n\n    # Make sure size is a list so we can iterate it and assign to it.\n    try:\n        size = list(size)\n    except TypeError:\n        size = [size]\n\n    # The number of samples in each time series\n    samples = size[-1]\n\n    # Calculate Frequencies (we asume a sample rate of one)\n    # Use fft functions for real output (-> hermitian spectrum)\n    f = rfftfreq(samples)\n\n    # Validate / normalise fmin\n    if 0 <= fmin <= 0.5:\n        fmin = max(fmin, 1./samples)    # Low frequency cutoff\n    else:\n        raise ValueError(\"fmin must be chosen between 0 and 0.5.\")\n\n    # Build scaling factors for all frequencies\n    s_scale = f\n    ix = np.sum(s_scale < fmin)   # Index of the cutoff\n    if ix and ix < len(s_scale):\n        s_scale[:ix] = s_scale[ix]\n    s_scale = s_scale**(-exponent/2.)\n\n    # Calculate theoretical output standard deviation from scaling\n    w = s_scale[1:].copy()\n    w[-1] *= (1 + (samples % 2)) / 2.    # correct f = +-0.5\n    sigma = 2 * np.sqrt(np.sum(w**2)) / samples\n\n    # Adjust size to generate one Fourier component per frequency\n    size[-1] = len(f)\n\n    # Add empty dimension(s) to broadcast s_scale along last\n    # dimension of generated random power + phase (below)\n    dims_to_add = len(size) - 1\n    s_scale = s_scale[(None,) * dims_to_add + (Ellipsis,)]\n\n    # Generate scaled random power + phase\n    if rng is None:\n        rng = np.random.default_rng()\n    sr = rng.normal(scale=s_scale, size=size)\n    si = rng.normal(scale=s_scale, size=size)\n\n    # If the signal length is even, frequencies +/- 0.5 are equal\n    # so the coefficient must be real.\n    if not (samples % 2):\n        si[..., -1] = 0\n        sr[..., -1] *= np.sqrt(2)    # Fix magnitude\n\n    # Regardless of signal length, the DC component must be real\n    si[..., 0] = 0\n    sr[..., 0] *= np.sqrt(2)    # Fix magnitude\n\n    # Combine power + corrected phase to Fourier components\n    s = sr + 1J * si\n\n    # Transform to real time series & scale to unit variance\n    y = irfft(s, n=samples, axis=-1) / sigma\n\n    return y","metadata":{"papermill":{"duration":0.027765,"end_time":"2024-02-06T21:33:08.656357","exception":false,"start_time":"2024-02-06T21:33:08.628592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:14:48.996946Z","iopub.execute_input":"2024-02-11T14:14:48.997214Z","iopub.status.idle":"2024-02-11T14:14:49.011196Z","shell.execute_reply.started":"2024-02-11T14:14:48.997186Z","shell.execute_reply":"2024-02-11T14:14:49.010319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ColoredNoiseProcess():\n    \"\"\"Colored noise implemented as a process that allows subsequent samples.\n    Implemented as a buffer; every \"chunksize[-1]\" items, a cut to a new time series starts.\n    \"\"\"\n\n    def __init__(self, beta=1, scale=1, chunksize=32768, largest_wavelength=256, rng=None):\n        self.beta = beta\n        if largest_wavelength is None:\n            self.minimum_frequency = 0\n        else:\n            self.minimum_frequency = 1 / largest_wavelength\n        self.scale = scale\n        self.rng = rng\n\n        # The last component of chunksize is the time index\n        try:\n            self.chunksize = list(chunksize)\n        except TypeError:\n            self.chunksize = [chunksize]\n        self.time_steps = self.chunksize[-1]\n\n        # Set first time-step such that buffer will be initialized\n        self.idx = self.time_steps\n\n    def sample(self):\n        self.idx += 1    # Next time step\n\n        # Refill buffer if depleted\n        if self.idx >= self.time_steps:\n            self.buffer = powerlaw_psd_gaussian(\n                exponent=self.beta, size=self.chunksize, fmin=self.minimum_frequency, rng=self.rng)\n            self.idx = 0\n\n        return self.scale * self.buffer[..., self.idx]","metadata":{"papermill":{"duration":0.023408,"end_time":"2024-02-06T21:33:08.690188","exception":false,"start_time":"2024-02-06T21:33:08.666780","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:14:49.014129Z","iopub.execute_input":"2024-02-11T14:14:49.014382Z","iopub.status.idle":"2024-02-11T14:14:49.030112Z","shell.execute_reply.started":"2024-02-11T14:14:49.014361Z","shell.execute_reply":"2024-02-11T14:14:49.029342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from stable_baselines3.common.distributions import SquashedDiagGaussianDistribution\nfrom stable_baselines3.common.noise import ActionNoise\n\nclass SquashedDiagCNDistribution(SquashedDiagGaussianDistribution):\n    \"\"\"\n    Colored Noise distribution with diagonal covariance matrix, followed by a squashing function (tanh) to ensure\n    bounds. Used for Soft Actor-Critic with colored noise exploration in lieu of SquashedDiagGaussianDistribution.\n\n    :param action_dim: Dimension of the action space.\n    :param epsilon: small value to avoid NaN due to numerical imprecision.\n    \"\"\"\n\n    def __init__(self, action_dim: int, beta: np.ndarray, seq_len, epsilon: float = 1e-6, rng=None):\n        super().__init__(action_dim, epsilon)\n        self.cn_processes = [ColoredNoiseProcess(beta=b, chunksize=seq_len, largest_wavelength=None, rng=rng)\n                             for b in beta]\n\n    def sample(self) -> th.Tensor:\n        cn_sample = th.tensor([cnp.sample() for cnp in self.cn_processes]).float()\n        cn_sample = cn_sample.to(device)\n        self.gaussian_actions = self.distribution.mean + self.distribution.stddev*cn_sample\n        return th.tanh(self.gaussian_actions)\n    \n    \nclass ColoredActionNoise(ActionNoise):\n    \"\"\"Action noise using colored noise processes (independent for each action dimension).\"\"\"\n    def __init__(self, beta, sigma, seq_len, action_dim=None, rng=None):\n        super().__init__()\n        assert (action_dim is not None) == np.isscalar(beta), \\\n            \"`action_dim` has to be specified if and only if `beta` is a scalar.\"\n\n        self.sigma = np.full(action_dim or len(beta), sigma) if np.isscalar(sigma) else np.asarray(sigma)\n\n        if np.isscalar(beta):\n            self.beta = beta\n            self.gen = ColoredNoiseProcess(beta=self.beta, scale=self.sigma, size=(action_dim, seq_len), rng=rng)\n        else:\n            self.beta = np.asarray(beta)\n            self.gen = [ColoredNoiseProcess(beta=b, scale=s, size=seq_len, rng=rng)\n                        for b, s in zip(self.beta, self.sigma)]\n\n    def __call__(self) -> np.ndarray:\n        return self.gen.sample() if np.isscalar(self.beta) else np.asarray([g.sample() for g in self.gen])\n\n    def __repr__(self) -> str:\n        return f\"ColoredActionNoise(beta={self.beta}, sigma={self.sigma})\"","metadata":{"papermill":{"duration":13.516468,"end_time":"2024-02-06T21:33:22.217134","exception":false,"start_time":"2024-02-06T21:33:08.700666","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:14:49.031160Z","iopub.execute_input":"2024-02-11T14:14:49.031444Z","iopub.status.idle":"2024-02-11T14:15:01.308230Z","shell.execute_reply.started":"2024-02-11T14:14:49.031422Z","shell.execute_reply":"2024-02-11T14:15:01.307412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GenEnv():\n    \"\"\"Generate gym environment from string with new seed each time\"\"\"\n    def __init__(self, seed, sparse_reward=False, tonic=False):\n        self.env = DMCWrapper(\"walker\",\"run\")\n        self.sparse_reward = sparse_reward\n        self.tonic = tonic\n        self.seed = seed\n        \n\n    def __call__(self, get_policy=False):\n        policy = \"MlpPolicy\"\n        env = DMCWrapper(\"walker\",\"run\")\n\n        if self.sparse_reward:\n            env.step_ = env.step\n\n            def step(env, a):\n                obs, _, done, info = env.step_(a)\n                return obs, int(info['goal_achieved']), done, info\n\n            env.step = MethodType(step, env)\n\n        self.seed += 1    # Change seed such that it is different each time the environment is created\n\n        if get_policy:\n            return env, policy\n        return env","metadata":{"papermill":{"duration":0.021752,"end_time":"2024-02-06T21:33:22.249217","exception":false,"start_time":"2024-02-06T21:33:22.227465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:37:16.772089Z","iopub.execute_input":"2024-02-11T14:37:16.772428Z","iopub.status.idle":"2024-02-11T14:37:16.779961Z","shell.execute_reply.started":"2024-02-11T14:37:16.772403Z","shell.execute_reply":"2024-02-11T14:37:16.779054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from stable_baselines3.common.callbacks import BaseCallback\n\nclass MonitorCallback(BaseCallback):\n    \"\"\"Simple SB3 callback for monitoring episode returns and lengths. Also shows a progress bar.\"\"\"\n    def __init__(self, gen_env, save=False, eval_every=10_000, n_eval=5):\n        super().__init__()\n        self.save = save\n        self.env = gen_env()\n        self.eval_every = eval_every    # Every eval_every interactions, commence evaluation step\n        self.n_eval = n_eval            # Number of evaluation episodes per evaluation step\n        self.episode_returns = []\n        self.episode_lengths = []\n        self.evaluation_returns = []\n        self.monitor = {'episode_returns': self.episode_returns, 'episode_lengths': self.episode_lengths,\n                        'evaluation_returns': self.evaluation_returns}\n\n    def _on_training_start(self):\n        self.n_actions = self.training_env.action_space.shape[-1]\n        self.episode_returns.append(0)\n        self.episode_lengths.append(0)\n\n        # Progress bar\n\n    def _on_training_end(self):\n        # Save data and close progress bar\n        pass\n\n    def _on_step(self):\n\n        # Store reward\n        self.episode_returns[-1] += self.locals['rewards'].item()\n        self.episode_lengths[-1] += 1\n        if self.locals['dones'].item():\n            self.episode_returns.append(0)\n            self.episode_lengths.append(0)\n\n        # Evaluation Rollouts\n        if self.num_timesteps == 1 or self.num_timesteps % self.eval_every == 0:\n            returns = np.zeros(self.n_eval)\n            for i in range(self.n_eval):\n                obs = self.env.reset()\n                done = False\n                while not done:\n                    action = self.model.predict(obs, deterministic=True)[0]\n                    obs, reward, done, _= self.env.step(action)\n                    returns[i] += reward\n            self.evaluation_returns.append((self.num_timesteps, returns))\n\n\nclass ScheduledColoredNoise(MonitorCallback):\n    \"\"\"Linear scheduling from colors[0] to colors[1]\"\"\"\n    def __init__(self, gen_env, save=False, colors=(2, 0), method='linear', noise_scale=0.3, len_rollout=10_000,\n                 rng=None, **monitor_kwargs):\n        super().__init__(gen_env, save, **monitor_kwargs)\n        self.colors = colors\n        self.method = method              # 'linear' or 'atanh' scheduling\n        self.noise_scale = noise_scale    # Colored noise process std\n        self.len_rollout = len_rollout    # Number of interactions per rollout\n        self.i = 0                        # Iteration counter\n        self.rng = rng                    # Random number generator\n\n        # Monitoring\n        self.chosen_colors = []\n        self.monitor['colors'] = self.chosen_colors\n\n    def _on_training_start(self):\n        super()._on_training_start()\n\n        # Initialize agent noise\n        self.beta = self.update_beta()\n\n    def set_beta(self, beta, seq_len):\n        if isinstance(self.model, SAC):\n            # State-dependent action noise is a bit more difficult\n            self.model.actor.action_dist = SquashedDiagCNDistribution(\n                self.n_actions, beta, seq_len, rng=self.rng)\n        else:\n            # For TD3 or other non-state dependent action noise agents\n            self.model.action_noise = ColoredActionNoise(\n                beta, self.noise_scale * np.ones(self.n_actions), seq_len, rng=self.rng)\n\n    def update_beta(self):\n        \"\"\"Select new beta parameter (randomly)\"\"\"\n        # Calculate and apply beta\n        x = self.num_timesteps / self.locals['total_timesteps']\n        if self.method == 'linear':\n            beta = (1 - x)*self.colors[0] + x*self.colors[1]\n        elif self.method == 'atanh':\n            beta = np.clip(np.arctanh(min(1 - x, 1 - 1e-6)), 0, 4)\n        elif self.method == 'cosine':\n            beta = self.colors[1] + 0.5 * (self.colors[0]-self.colors[1]) * (1+math.cos(math.pi*x))\n        beta *= np.ones(self.n_actions)\n        self.set_beta(beta, self.len_rollout)\n\n        # Monitoring\n        self.chosen_colors.append(beta)\n\n        return beta\n\n    def _on_step(self):\n        super()._on_step()\n\n        # Check if rollout is finished\n        i = self.num_timesteps // self.len_rollout\n        if i == self.i:\n            return\n        self.i = i\n\n        # Select new beta and change noise process\n        self.beta = self.update_beta()","metadata":{"papermill":{"duration":0.037943,"end_time":"2024-02-06T21:33:22.297439","exception":false,"start_time":"2024-02-06T21:33:22.259496","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:37:18.659004Z","iopub.execute_input":"2024-02-11T14:37:18.659808Z","iopub.status.idle":"2024-02-11T14:37:18.681192Z","shell.execute_reply.started":"2024-02-11T14:37:18.659777Z","shell.execute_reply":"2024-02-11T14:37:18.680341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def linear(x,start,stop):\n    return (1-x)*start + x*stop","metadata":{"papermill":{"duration":0.018251,"end_time":"2024-02-06T21:33:22.325880","exception":false,"start_time":"2024-02-06T21:33:22.307629","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:15:01.358460Z","iopub.execute_input":"2024-02-11T14:15:01.358756Z","iopub.status.idle":"2024-02-11T14:15:01.372945Z","shell.execute_reply.started":"2024-02-11T14:15:01.358730Z","shell.execute_reply":"2024-02-11T14:15:01.372105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\ndef cosine(x,start,stop):\n    return stop + 0.5 * (start-stop) * (1+math.cos(math.pi*x))","metadata":{"papermill":{"duration":0.01814,"end_time":"2024-02-06T21:33:22.354145","exception":false,"start_time":"2024-02-06T21:33:22.336005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:15:01.374103Z","iopub.execute_input":"2024-02-11T14:15:01.374704Z","iopub.status.idle":"2024-02-11T14:15:01.384025Z","shell.execute_reply.started":"2024-02-11T14:15:01.374674Z","shell.execute_reply":"2024-02-11T14:15:01.383285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def atanh(x,start,stop):\n    return np.clip(np.arctanh(min(1 - x, 1 - 1e-6)), 0, 4)","metadata":{"papermill":{"duration":0.018077,"end_time":"2024-02-06T21:33:22.382342","exception":false,"start_time":"2024-02-06T21:33:22.364265","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:15:01.384965Z","iopub.execute_input":"2024-02-11T14:15:01.385237Z","iopub.status.idle":"2024-02-11T14:15:01.393532Z","shell.execute_reply.started":"2024-02-11T14:15:01.385215Z","shell.execute_reply":"2024-02-11T14:15:01.392709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\nimport numpy as np\nfrom stable_baselines3 import SAC\nimport time\nfrom tqdm import tqdm\n\n# Define a function to evaluate an episode\ndef evaluate_episode(model, env):\n    obs = env.reset()\n    done = False\n    total_reward = 0.0\n    steps=0\n    while steps<1000 and not done:\n        action, _ = model.predict(obs, deterministic=True)\n        obs, reward, done, _ = env.step(action)\n        total_reward += reward\n        steps+=1\n    return total_reward\n\n# Reproducibility\nseed = 69\nnp.random.seed(seed)\nth.manual_seed(seed)\nrng = np.random.default_rng(seed)\n\n# Initialize environment\n\ngen_env = GenEnv(seed=420)\ndir_ = '.'\nnoise_scale = 0.3\nenv = gen_env(get_policy=False)\nep = 100\nrng = np.random.default_rng(seed = 3939)\naction_dim = env.action_space.shape[-1]\nseq_len = 1000\n\nstart_linear = 2\nstop_linear = 2\nstart_atanh = 2\nstop_atanh = 2\nstart_cosine = 2\nstop_cosine = 2\n\n# Initialize agents\nmodel_linear = SAC(\"MlpPolicy\", env, seed = seed)\nmodel_atanh = SAC(\"MlpPolicy\", env, seed = seed)\nmodel_cosine = SAC(\"MlpPolicy\", env, seed=seed)\n\n\n# Training parameters\ntotal_timesteps = 1000000\neval_frequency = 10000 # Evaluate every 104 interactions\neval_rollouts = 5\n\nwandb.init(\n    project=\"Pinkie\",\n    config = {\n    \"Total_timesteps\": total_timesteps,\n    \"Eval_frequency\": eval_frequency,\n    \"Eval_rollouts\": eval_rollouts\n    }\n)\n\n#Final average performances\navg_linear=0.0\navg_cosine=0.0\navg_atanh=0.0\nfinal_linear=0.0\nfinal_cosine=0.0\nfinal_atanh=0.0\n\n# Train agents with evaluation\ntimesteps_so_far = 0\n# for timesteps_so_far in tqdm(range(0,total_timesteps,eval_frequency)):\nwhile timesteps_so_far < total_timesteps:\n    \n    timesteps_so_far += eval_frequency\n    x = timesteps_so_far/total_timesteps\n    start_linear = stop_linear\n    stop_linear = linear(x,2,0)\n    callback_linear = ScheduledColoredNoise(\n                gen_env, dir_, (start_linear, stop_linear), 'linear', noise_scale,\n                ep, rng)\n    \n    t1 = time.time()\n    # Train the default noise model\n#     print(model_linear.actor.action_dist.gen.beta)\n    model_linear.learn(total_timesteps=eval_frequency, log_interval = 1,callback = callback_linear )\n#     print(model_linear.actor.action_dist.gen.beta)\n    t2 = time.time()\n\n    # Evaluate the default noise model\n    mean_return_linear = 0.0\n    for _ in range(eval_rollouts):\n        mean_return_linear += evaluate_episode(model_linear, env)\n    mean_return_linear /= eval_rollouts\n    avg_linear+=mean_return_linear\n    if(timesteps_so_far>=0.95*total_timesteps):\n        final_linear+=mean_return_linear\n\n    print(f\"Return (Linear): {mean_return_linear}\")\n    print(f\"Time taken (Linear Model): {t2 - t1:.2f} seconds\")\n    print(f\"Timesteps: {timesteps_so_far}, Mean Return: {mean_return_linear}\")\n    \n    \n    start_cosine = stop_cosine\n    stop_cosine = cosine(x,2,0)\n    callback_cosine = ScheduledColoredNoise(\n                gen_env, dir_, (start_cosine, stop_cosine), 'linear', noise_scale,\n                ep, rng)\n    \n    t1 = time.time()\n    # Train the default noise model\n#     print(model_cosine.actor.action_dist.gen.beta)\n    model_cosine.learn(total_timesteps=eval_frequency,log_interval = 1, callback = callback_cosine)\n#     print(model_cosine.actor.action_dist.gen.beta)\n    t2 = time.time()\n\n    # Evaluate the default noise model\n    mean_return_cosine = 0.0\n    for _ in range(eval_rollouts):\n        mean_return_cosine += evaluate_episode(model_cosine, env)\n    mean_return_cosine /= eval_rollouts\n    avg_cosine+=mean_return_cosine\n    if(timesteps_so_far>=0.95*total_timesteps):\n        final_cosine+=mean_return_cosine\n\n    print(f\"Return (Cosine): {mean_return_cosine}\")\n    print(f\"Time taken (Cosine Model): {t2 - t1:.2f} seconds\")\n    print(f\"Timesteps: {timesteps_so_far}, Mean Return: {mean_return_cosine}\")\n    \n    start_atanh = stop_atanh\n    stop_atanh = atanh(x,2,0)\n    callback_atanh = ScheduledColoredNoise(\n                gen_env, dir_, (start_atanh, stop_atanh), 'linear', noise_scale,\n                ep, rng)\n    \n    t1 = time.time()\n    # Train the default noise model\n#     print(model_atanh.actor.action_dist.gen.beta)\n    model_atanh.learn(total_timesteps=eval_frequency,log_interval = 1,callback = callback_atanh)\n#     print(model_atanh.actor.action_dist.gen.beta)\n    t2 = time.time()\n\n    # Evaluate the default noise model\n    mean_return_atanh = 0.0\n    for _ in range(eval_rollouts):\n        mean_return_atanh += evaluate_episode(model_atanh, env)\n    mean_return_atanh /= eval_rollouts\n    avg_atanh+=mean_return_atanh\n    if(timesteps_so_far>=0.95*total_timesteps):\n        final_atanh+=mean_return_atanh\n\n    print(f\"Return (Atanh): {mean_return_atanh}\")\n    print(f\"Time taken (Atanh Model): {t2 - t1:.2f} seconds\")\n    print(f\"Timesteps: {timesteps_so_far}, Mean Return: {mean_return_atanh}\")\n    \n    wandb.log({\n        \"mean_return_linear\": mean_return_linear,\n        \"timesteps_so_far\": timesteps_so_far,\n        \"mean_return_cosine\": mean_return_cosine,\n        \"mean_return_atanh\": mean_return_atanh,\n        \"linear_beta\": stop_linear,\n        \"cosine_beta\": stop_cosine,\n        \"atanh_beta\": stop_atanh\n    })\n\navg_linear/=(total_timesteps/eval_frequency)\navg_cosine/=(total_timesteps/eval_frequency)\navg_atanh/=(total_timesteps/eval_frequency)\n\nfinal_linear/=(0.05*total_timesteps/eval_frequency)\nfinal_cosine/=(0.05*total_timesteps/eval_frequency)\nfinal_atanh/=(0.05*total_timesteps/eval_frequency)\n\nwandb.log({\n    \"final_linear\": final_linear,\n    \"final_cosine\": final_cosine,\n    \"final_atanh\": final_atanh,\n    \"avg_linear\": avg_linear,\n    \"avg_cosine\": avg_cosine,\n    \"avg_atanh\": avg_atanh\n})\n\nprint(\"Mean:\")\nprint(f\"Linear:{avg_linear}           Cosine:{avg_cosine}             atanh:{avg_atanh}\")\nprint(\"Final:\")\nprint(f\"Linear:{final_linear}           Cosine:{final_cosine}             atanh:{final_atanh}\")","metadata":{"papermill":{"duration":41797.915242,"end_time":"2024-02-07T09:10:00.307684","exception":true,"start_time":"2024-02-06T21:33:22.392442","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-11T14:37:21.030550Z","iopub.execute_input":"2024-02-11T14:37:21.031025Z"},"trusted":true},"execution_count":null,"outputs":[]}]}